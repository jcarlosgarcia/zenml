# Software requirements and stack components that are needed
# by tests can be defined globally here and referenced by name in
# environments or per-test configurations or passed to pytest directly using the
# `--requirements` command line argument.
# 
# When referenced in an environment, the stack requirements are
# provisioned globally when the environment is setup. When referenced in a test,
# the requirements are interpreted as a test-specific requirements.
#
# The following fields can be configured in the test requirements:
#
# - name: The name of the configuration entry. This is needed to reference the
#   requirements in environments or test configurations.
# - integrations: A list of ZenML integrations that are required for the test to
#   run.
# - packages: A list of extra Python packages that are required for the test to
#   run. Each entry can be either a package name or a package name and version
#   specifier (e.g. `numpy==1.19.5`).
# - system_tools: A list of system_tools tools that are required for the test
#   to run. Each entry designates a binary that must be available in the system
#   path (e.g. `docker` or `kubectl`).
# - system_os: A list of operating systems that the test can run on. Valid
#   values are `linux`, `macos`, and `windows`.
# - stacks: Optional list of ZenML stack components that are required for the
#   test to run. Each entry contains the following fields:
#   - type (mandatory): The type of stack component required.
#   - flavor (optional): The flavor of stack component required. If not
#     specified, any flavor of the given type is accepted. When specified, the
#     integration associated with the stack component flavor is implicitly added
#     to the test requirements.
#   - configuration (optional): A dictionary of configuration options that must
#     be set for the stack component to be accepted. The values may reference
#     secrets that are defined in the test configuration or as environment
#     variables using the `{{SECRET_NAME_OR_ENV_VAR}}` syntax.
#
# Note that the integrations, packages and system tools requirements are not
# installed automatically. The user is expected to install them in the host OS
# and/or current virtual environment. The test framework only checks for their
# presence and fails the environment setup (when used or referenced in
# environments) or skips the test (when used or referenced in tests) if they are
# not installed.
#
# Example:
#
#  ```
#  requirements:
#    - name: example
#      integrations:
#        - pytorch
#        - xgboost
#      packages:
#        - numpy==1.19.5
#        - pandas
#      system_tools:
#        - docker
#        - kubectl
#      system_os:
#        - linux
#        - macos
#      stacks:
#        - type: experiment_tracker
#          flavor: mlflow
#          configuration:
#            nested: true
#        - type: model_deployer
#          flavor: seldon
#  ```
#
requirements:

    # Data validators do not require external resources, infrastructure
    # or services to be set up and can be provisioned on-demand on any
    # environment and combined with any other stack component (local or remote)
    # and with any server deployment (local or remote).
  - name: data-validators
    stacks:
      - name: deepchecks
        type: data_validator
        flavor: deepchecks
      - name: evidently
        type: data_validator
        flavor: evidently
      - name: great_expectations
        type: data_validator
        flavor: great_expectations
      - name: whylogs
        type: data_validator
        flavor: whylogs

    # Local kubeflow orchestrator components
  - name: kubeflow-local
    system_tools:
      - docker
      - kubectl
      - k3d
    stacks:
      - name: kubeflow-local
        type: orchestrator
        flavor: kubeflow
        configuration:
          synchronous: true
      - name: k3d-local
        type: container_registry
        flavor: local
        configuration:
          url: localhost:5000

    # Local docker orchestrator
  - name: docker-local
    system_tools:
      - docker
    stacks:
      - name: docker-local
        type: orchestrator
        flavor: docker_local
        configuration:
          synchronous: true

    # Local airflow orchestrator
  - name: airflow-local
    packages:
      - apache-airflow-providers-docker
    stacks:
      - name: airflow-local
        type: orchestrator
        flavor: airflow
        configuration:
          local: true
          synchronous: true

    # Local mlflow experiment tracker
  - name: mlflow-local-tracker
    stacks:
      - name: mlflow-local
        type: experiment_tracker
        flavor: mlflow

    # Local mlflow model deployer
  - name: mlflow-local-deployer
    system_os:
      - linux
      - macos
    stacks:
      - name: mlflow-local
        type: model_deployer
        flavor: mlflow

    # Local secrets manager
  - name: local-secrets-manager
    stacks:
      - name: local
        type: secrets_manager
        flavor: local
